{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e529cc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (697790446.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    cat 102T_V350286221_L02_33_444771_1.fastq.gz 102T_V350286221_L03_33_444771_1.fastq.gz > 102T_444771_1.fastq.gz\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Descomprimir el completo \n",
    "\n",
    "UNZIP_DISABLE_ZIPBOMB_DETECTION=TRUE unzip archivo_comprimido_896.zip -d /home/yordonez/Danny_OV_WES/\n",
    "\n",
    "# Para pasar de fastq.gz a fastq\n",
    "gunzip *fastq.gz\n",
    "\n",
    "### Si es necesario concatenar varios archivos de la misma muestra:\n",
    "cat 102T_V350286221_L02_33_444771_1.fastq.gz 102T_V350286221_L03_33_444771_1.fastq.gz > 102T_444771_1.fastq.gz\n",
    "cat 102T_V350286221_L02_33_444771_2.fastq.gz 102T_V350286221_L03_33_444771_2.fastq.gz > 102T_444771_2.fastq.gz\n",
    "\n",
    "\n",
    "###concatenar todo\n",
    "cat \"CO-H,243121\"*_L*_1.fastq > CO-E_243121_all_R1_fastq\n",
    "cat \"CO-E,275235\"*_L*_1.fastq > CO-E_275235_all_R1_fastq\n",
    "\n",
    "###Descargar en el pc:\n",
    "scp -r yordonez3@biocompjord01.biosci.gatech.edu:/home/yordonez3/Danny_OV_WES/concatenated_fastq_faltantes/fastqc_results C:\\\\Users\\\\pmorales\\\\Downloads\n",
    "\n",
    "###Descargar en el servidor:\n",
    "scp \"C:\\Users\\pmorales\\Downloads\\archivo_comprimido_1044.zip\" yordonez3@bio-compjord01:/home/yordonez3/Danny_OV_WES/concatenated_fastq_faltantes/\n",
    "scp \"C:\\Users\\pmorales\\Downloads\\archivo_comprimido_1044.zip\" yordonez3@130.207.66.26:/home/yordonez3/Danny_OV_WES/concatenated_fastq_faltantes/\n",
    "\n",
    "Se procede a alinear con el genoma humano despues del control de calidad.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafaefed-2791-44b6-91b0-ac38e5a3b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. CONTROL DE CALIDAD1. ### FASTQC raw\n",
    "\n",
    "conda activate fastqc_env\n",
    "fastqc -o /home/yordonez3/Danny_OV_WES/concatenated_fastq/OVARIO *.fastq\n",
    "\n",
    "#### Para correr muestras faltantes\n",
    "\n",
    "# Activar el entorno de conda\n",
    "conda activate fastqc_env\n",
    "\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/fastqc_results\"\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/OVARIO\"\n",
    "\n",
    "# Iterar sobre los archivos .fastq.gz\n",
    "for file in $input_dir/*_all_R2.fastq; do\n",
    "    # Obtener el nombre del archivo sin la extensi√≥n\n",
    "    filename=$(basename \"$file\" .fastq)\n",
    "\n",
    "    # Verificar si los archivos de salida ya existen\n",
    "    if [[ ! -f \"$output_dir/$filename\"_fastqc.html && ! -f \"$output_dir/$filename\"_fastqc.zip ]]; then\n",
    "        # Si no existen los archivos de salida, ejecutar fastqc\n",
    "        echo \"Procesando $filename...\"\n",
    "        fastqc -o \"$output_dir\" \"$file\"\n",
    "    else\n",
    "        # Si los archivos de salida ya existen, saltar esta muestra\n",
    "        echo \"La muestra $filename ya ha sido procesada. Saltando...\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "\n",
    "2. ### MULTIQC raw\n",
    "multiqc total_samples_pool/EXOMA/FastQC_raw_ex -o total_samples_pool/EXOMA/MultiQC_raw_ex\n",
    "\n",
    "2. ### MULTIQC raw\n",
    "multiqc /home/yordonez3/Danny_OV_WES/concatenated_fastq_faltantes/fastqc_results/MultiQC_raw_ex\n",
    "\n",
    "3. ###DescargarMultiQC en mi pc\n",
    "scp -r yordonez3@bio-compjord01.biosci.gatech.edu:/home/yordonez3/Danny_OV_WES/concatenated_fastq_faltantes/ multiqc_data_1 /C:/Users/pmorales/Downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce26ee5-74de-44c1-bc46-90c6a0137f56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3430739851.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    ACA QUEDE#samples=($(ls $input_dir/*_1.fastq.gz | sed 's/_1.fastq.gz//'))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "### KRAKEN 2\n",
    "\n",
    "# Directorio de entrada y salida\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq_faltantes/\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/kraken2_results\"\n",
    "kraken_db=\"/home/yordonez3/Danny_OV_WES/kraken2\"\n",
    "\n",
    "# Obtener los nombres de las muestras con dos patrones posibles (R1/R2 y _1/_2)\n",
    "samples=($(ls $input_dir/*_R1.fastq | sed 's/_R1.fastq//'))\n",
    "\n",
    "# Bucle para procesar cada muestra\n",
    "for sample_path in \"${samples[@]}\"; do\n",
    "    sample=$(basename \"$sample_path\")\n",
    "    read1_file=\"${sample}_R1.fastq\"\n",
    "    read2_file=\"${sample}_R2.fastq\"\n",
    "\n",
    "    # Ejecutar Kraken 2\n",
    "    kraken2 --db /home/yordonez3/Danny_OV_WES/kraken2 \\\n",
    "            --threads 10 \\\n",
    "            --output \"${output_dir}/${sample}_kraken_output.txt\" \\\n",
    "            --report \"${output_dir}/${sample}_kraken_report.txt\" \\\n",
    "            \"$input_dir/$read1_file\" \"$input_dir/$read2_file\"\n",
    "    \n",
    "    echo \"Clasificaci√≥n completada para la muestra $sample\"\n",
    "done\n",
    "\n",
    "## Revisar resultados\n",
    "multiqc kraken2 -o MQCkraken\n",
    "\n",
    "### 3. ALINEAMIENTO BWA \n",
    "\n",
    "# 1. Indexar gemona de referencia \n",
    "#Toda la info del genoma : http://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/\n",
    "        \n",
    "# para descargarlo\n",
    "wget http://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/hg38.fa.gz\n",
    "gunzip hg38.fa.gz\n",
    "du -h hg38.fa #para saber el peso (3.1GB)\n",
    "\n",
    "# descargar el archivo de anotaciones\n",
    "wget http://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/genes/hg38.refGene.gtf.gz\n",
    "gunzip hg38.refGene.gtf.gz\n",
    "\n",
    "#Para crear el index\n",
    "# Entrar a la carpeta de salida y crear un enlace hacia donde esta el genoma\n",
    "ln -s /home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/GRCh38_Gencode31/hg38.fa \n",
    "\n",
    "#Activar entorno conda\n",
    "Conda activate\n",
    "\n",
    "#Indexar: Indexar un genoma con bwa es preparar el archivo de referencia (por ejemplo, hg38.fa) para que el programa pueda buscar en √©l r√°pidamente las coincidencias con tus secuencias (fastq).\n",
    "bwa index hg38.fa\n",
    "\n",
    "#Se generan archivos:\n",
    "#hg38.fa.amb\n",
    "#hg38.fa.ann\n",
    "#hg38.fa.bwt\n",
    "#hg38.fa.pac\n",
    "#hg38.fa.sa\n",
    "\n",
    "## Correr el alineamiento\n",
    "\n",
    "#Primero crear carpeta de salida si no existe\n",
    "mkdir -p \"OUTPUT_DIR\"\n",
    "\n",
    "# Rutas\n",
    "FASTQ_DIR=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq_faltantes\"\n",
    "REF_GENOME=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/GRCh38_Gencode31/hg38.fa\"\n",
    "OUTPUT_DIR=\"$FASTQ_DIR/BWA_data1\"\n",
    "REF_DIR=\"/home/yordonez3/Danny_OV_WES/GRCh38_Gencode31/index_BWA\"\n",
    "\n",
    "\n",
    "mkdir -p \"$OUTPUT_DIR\"\n",
    "\n",
    "# Iterar sobre todos los archivos *_R1.fastq\n",
    "for R1 in \"$FASTQ_DIR\"/*all_R1.fastq; do\n",
    "    # Obtener nombre base (quita solo el _R1.fastq)\n",
    "    base=$(basename \"$R1\" _R1.fastq)\n",
    "    \n",
    "    R2=\"$FASTQ_DIR/${base}all_R2.fastq\"\n",
    "    SAM=\"$OUTPUT_DIR/${base}.sam\"\n",
    "    BAM=\"$OUTPUT_DIR/${base}.bam\"\n",
    "    SORTED=\"$OUTPUT_DIR/${base}_sorted.bam\"\n",
    "\n",
    "    echo \"üß¨ Procesando muestra: $base\"\n",
    "\n",
    "    # Alineamiento\n",
    "    bwa mem -t 8 \"$REF_GENOME\" \"$R1\" \"$R2\" > \"$SAM\"\n",
    "\n",
    "    # Convertir SAM a BAM\n",
    "    samtools view -bS \"$SAM\" > \"$BAM\"\n",
    "\n",
    "    # Ordenar BAM\n",
    "    samtools sort \"$BAM\" -o \"$SORTED\"\n",
    " \n",
    "# Se ve algo como:\n",
    "[bam_sort_core] merging from 23 files and 1 in-memory blocks...\n",
    "\n",
    "    # Indexar BAM\n",
    "    samtools index \"$SORTED\"\n",
    "\n",
    "    echo \"‚úÖ Finalizado: $base\"\n",
    "done\n",
    "\n",
    "echo \"üéâ Proceso completo para todas las muestras.\"\n",
    "\n",
    "############## con las muestras faltantes se hizo este ajuste\n",
    "\n",
    "# Definir rutas\n",
    "FASTQ_DIR=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq_faltantes\"\n",
    "REF_GENOME=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "OUTPUT_DIR=\"$FASTQ_DIR/BWA_data1\"\n",
    "\n",
    "# Crear carpeta de salida si no existe\n",
    "mkdir -p \"$OUTPUT_DIR\"\n",
    "\n",
    "# Activar entorno conda si lo usas (descomenta y ajusta el nombre si aplica)\n",
    "# conda activate bwa_env\n",
    "\n",
    "# Verificar si el √≠ndice BWA existe; si no, crearlo\n",
    "if [[ ! -f \"${REF_GENOME}.bwt\" ]]; then\n",
    "    echo \"El √≠ndice de BWA no se encuentra. Gener√°ndolo...\"\n",
    "    bwa index \"$REF_GENOME\"\n",
    "else\n",
    "    echo \"√çndice de BWA encontrado. Continuando...\"\n",
    "fi\n",
    "\n",
    "# Alinear todos los pares de archivos FASTQ\n",
    "for R1 in \"$FASTQ_DIR\"/*_R1.fastq; do\n",
    "    SAMPLE=$(basename \"$R1\" _R1.fastq)\n",
    "    R2=\"$FASTQ_DIR/${SAMPLE}_R2.fastq\"\n",
    "\n",
    "    # Verifica que el R2 exista\n",
    "    if [[ -f \"$R2\" ]]; then\n",
    "        echo \"Procesando muestra: $SAMPLE\"\n",
    "        bwa mem \"$REF_GENOME\" \"$R1\" \"$R2\" > \"$OUTPUT_DIR/${SAMPLE}.sam\"\n",
    "        echo \"‚úì Alineamiento completado para: $SAMPLE\"\n",
    "    else\n",
    "        echo \"‚ö† No se encontr√≥ el archivo R2 para la muestra $SAMPLE, se omite.\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"‚úÖ Todos los alineamientos han terminado.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f61947",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (313761294.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    samples=($(ls \"${input_dir}\"/*.bam | xargs -n 1 basename | sed 's/.bam//'))\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## PICARD\n",
    "\n",
    "#para obtener el archivo de referencia:\n",
    "## wget http://hgdownload.cse.ucsc.edu/goldenPath/hg38/database/refFlat.txt.gz\n",
    "\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/BWA_data_faltantes\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/picard_exo\"\n",
    "reference_genome=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "samples=($(ls \"${input_dir}\"/*.bam | xargs -n 1 basename | sed 's/.bam//'))\n",
    "\n",
    "# Bucle para procesar cada muestra\n",
    "for sample_name in \"${samples[@]}\"; do\n",
    "    input_bam=\"${input_dir}/${sample_name}.bam\"\n",
    "    sorted_bam=\"${output_dir}/${sample_name}_sorted.bam\"\n",
    "    output_file=\"${output_dir}/${sample_name}_alignment_Metrics.txt\"\n",
    "\n",
    "    # Ordenar el archivo BAM\n",
    "    java -Xmx64G -jar /home/yordonez3/picard/picard.jar SortSam \\\n",
    "        INPUT=\"$input_bam\" \\\n",
    "        OUTPUT=\"$sorted_bam\" \\\n",
    "        SORT_ORDER=coordinate\n",
    "\n",
    "    # Recopilar m√©tricas de alineaci√≥n\n",
    "    java -Xmx64G -jar /home/yordonez3/picard/picard.jar CollectAlignmentSummaryMetrics \\\n",
    "        REFERENCE_SEQUENCE=\"$reference_genome\" \\\n",
    "        INPUT=\"$sorted_bam\" \\\n",
    "        OUTPUT=\"$output_file\"\n",
    "\n",
    "    echo \"Picard completado para la muestra $sample_name\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f116fa2d-fba7-4655-a78a-155b1eacffbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1734690619.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    mkdir -p \"$output_dir\"\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Agregar READ GROUPS a todos los BAM recalibrados\n",
    "\n",
    "PICARD_JAR=\"$HOME/picard/picard.jar\"  # Cambia esto si tu picard est√° en otra ruta\n",
    "bam_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/picard_exo\"\n",
    "output_dir=\"${bam_dir}/with_read_groups_faltantes\"\n",
    "\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# ==== PROCESAMIENTO ====\n",
    "echo \"üöÄ Agregando Read Groups a los archivos BAM...\"\n",
    "\n",
    "for bam_file in \"$bam_dir\"/*_dedup.bam; do\n",
    "  if [[ -f \"$bam_file\" ]]; then\n",
    "    filename=$(basename \"$bam_file\" .bam)\n",
    "    \n",
    "    # Datos del read group (puedes adaptarlos si tienes info m√°s precisa)\n",
    "    RGID=\"$filename\"\n",
    "    RGLB=\"lib1\"\n",
    "    RGPL=\"ILLUMINA\"\n",
    "    RGPU=\"unit1\"\n",
    "    RGSM=\"$filename\"\n",
    "\n",
    "    output_bam=\"${output_dir}/${filename}_rg.bam\"\n",
    "\n",
    "    echo \"‚û°Ô∏è  Procesando $filename...\"\n",
    "\n",
    "    java -jar \"$PICARD_JAR\" AddOrReplaceReadGroups \\\n",
    "      I=\"$bam_file\" \\\n",
    "      O=\"$output_bam\" \\\n",
    "      RGID=\"$RGID\" \\\n",
    "      RGLB=\"$RGLB\" \\\n",
    "      RGPL=\"$RGPL\" \\\n",
    "      RGPU=\"$RGPU\" \\\n",
    "      RGSM=\"$RGSM\" \\\n",
    "      SORT_ORDER=coordinate \\\n",
    "      VALIDATION_STRINGENCY=LENIENT \\\n",
    "      CREATE_INDEX=true \\\n",
    "      || { echo \"‚ùå Error al procesar $filename\"; continue; }\n",
    "\n",
    "    echo \"‚úÖ Read Group agregado: $output_bam\"\n",
    "  fi\n",
    "done\n",
    "\n",
    "echo \"üéâ Proceso finalizado. Los BAM con RG est√°n en: $output_dir\"\n",
    "\n",
    "Si faltan archivos por procesar:\n",
    "\n",
    "PICARD_JAR=\"$HOME/picard/picard.jar\"  # Cambia esto si tu picard est√° en otra ruta\n",
    "bam_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/picard_exo\"\n",
    "output_dir=\"${bam_dir}/with_read_groups\"\n",
    "\n",
    "mkdir -p \"$output_dir\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b962250f-ee2e-4bdd-a8db-be254961e367",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (544066919.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    mkdir -p \"$output_dir\"\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Agregar READ GROUPS a todos los BAM recalibrados\n",
    "\n",
    "PICARD_JAR=\"$HOME/picard/picard.jar\"  # Cambia esto si tu picard est√° en otra ruta\n",
    "bam_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/picard_exo\"\n",
    "output_dir=\"${bam_dir}/with_read_groups_faltantes\"\n",
    "\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# ==== PROCESAMIENTO ====\n",
    "echo \"üöÄ Agregando Read Groups a los archivos BAM...\"\n",
    "\n",
    "for bam_file in \"$bam_dir\"/*_dedup.bam; do\n",
    "  if [[ -f \"$bam_file\" ]]; then\n",
    "    filename=$(basename \"$bam_file\" .bam)\n",
    "    \n",
    "    # Datos del read group (puedes adaptarlos si tienes info m√°s precisa)\n",
    "    RGID=\"$filename\"\n",
    "    RGLB=\"lib1\"\n",
    "    RGPL=\"ILLUMINA\"\n",
    "    RGPU=\"unit1\"\n",
    "    RGSM=\"$filename\"\n",
    "\n",
    "    output_bam=\"${output_dir}/${filename}_rg.bam\"\n",
    "\n",
    "# ‚ùóÔ∏è Verifica si el archivo ya existe\n",
    "    if [[ -f \"$output_bam\" ]]; then\n",
    "      echo \"‚è© Ya existe: $output_bam (omitido)\"\n",
    "      continue\n",
    "    fi\n",
    "\n",
    "    echo \"‚û°Ô∏è  Procesando $filename...\"\n",
    "\n",
    "    java -jar \"$PICARD_JAR\" AddOrReplaceReadGroups \\\n",
    "      I=\"$bam_file\" \\\n",
    "      O=\"$output_bam\" \\\n",
    "      RGID=\"$RGID\" \\\n",
    "      RGLB=\"$RGLB\" \\\n",
    "      RGPL=\"$RGPL\" \\\n",
    "      RGPU=\"$RGPU\" \\\n",
    "      RGSM=\"$RGSM\" \\\n",
    "      SORT_ORDER=coordinate \\\n",
    "      VALIDATION_STRINGENCY=LENIENT \\\n",
    "      CREATE_INDEX=true \\\n",
    "      || { echo \"‚ùå Error al procesar $filename\"; continue; }\n",
    "\n",
    "    echo \"‚úÖ Read Group agregado: $output_bam\"\n",
    "  fi\n",
    "done\n",
    "\n",
    "echo \"üéâ Proceso finalizado. Los BAM con RG est√°n en: $output_dir\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cd46ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (479067158.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    conda activate\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "## RECALIBRAR BASES\n",
    "\n",
    "bam_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/picard_exo/with_read_groups_faltantes\"\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "dbsnp=\"/home/yordonez3/bioconda3/gatk/Homo_sapiens_assembly38.dbsnp138.vcf\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/rec_bases\"\n",
    "gatk_path=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/BWA_data/apps/gatk-4.6.1.0\"\n",
    "\n",
    "#Importante instalar GATK-versuib ac\n",
    "conda activate\n",
    "conda install bioconda::gatk\n",
    "gatk --version\n",
    "\n",
    "#Si no funciona, instalar desde la pagina oficial:\n",
    "\n",
    "https://github.com/broadinstitute/gatk/releases/tag/4.6.1.0\n",
    "wget https://github.com/broadinstitute/gatk/releases/download/4.6.1.0/gatk-4.6.1.0.zip\n",
    "unzip gatk-4.6.1.0.zip\n",
    "gatk-4.6.1.0/gatk\n",
    "/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/BWA_data/apps/gatk-4.6.1.0\n",
    "\n",
    "#Instalar java, version reciente:\n",
    "conda install -c conda-forge openjdk=17\n",
    "java -version\n",
    "\n",
    "#si no funciona, instalar desde la pagina principal, descargar la version y en mi terminal:\n",
    "scp \"C:/Users/pmorales/Downloads/OpenJDK11U-jdk_ppc64_aix_hotspot_11.0.26_4.tar.gz\" yordonez3@bio-compjord01.biosci.gatech.edu:/home/yordonez3/Danny_OV_WES\n",
    "\n",
    "## ----------- CREAR DIRECTORIO DE SALIDA SI NO EXISTE -----------\n",
    "mkdir -p \"$output_dir\"\n",
    "# Descargar desde AdoptOpenJDK (ahora Eclipse Temurin) \n",
    "wget https://github.com/adoptium/temurin17-binaries/releases/download/jdk-17.0.10%2B7/OpenJDK17U-jdk_x64_linux_hotspot_17.0.10_7.tar.gz -O openjdk17.tar.gz\n",
    "\n",
    "# Crea el directorio donde se instalar√° Java:\n",
    "mkdir -p ~/java\n",
    "\n",
    "# Descomprimir el archivo descargado en ese directorio:\n",
    "tar export JAVA_HOME=$HOME/java/jdk-17.0.10+7 \n",
    "\n",
    "# Configurar las variables de entorno en el archivo .bashrc:\n",
    "echo export JAVA_HOME=$HOME/java/jdk-17.0.10+7 >> ~/.bashrc\n",
    "echo 'export PATH=$JAVA_HOME/bin:$PATH' >> ~/.bashrc\n",
    "export GATK_HOME=$HOME/Danny_OV_WES/concatenated_fastq/BWA_data/apps/gatk-4.6.1.0\n",
    "export PATH=$GATK_HOME:$PATH\n",
    "\n",
    "java -version \n",
    "\n",
    "# Aplica los cambios en tu sesi√≥n actual:\n",
    "source ~/.bashrc\n",
    "Verifica que Java est√© correctamente instalado:\n",
    "java -version\n",
    "\n",
    "# Descargar desde AdoptOpenJDK\n",
    "wget https://github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.19%2B7/OpenJDK11U-jdk_x64_linux_hotspot_11.0.19_7.tar.gz\n",
    "\n",
    "# Iterar sobre los archivos BAM sin duplicados\n",
    "for bam_file in \"$bam_dir\"/*-noDups.bam; do\n",
    "\n",
    "    # Extraer el nombre base del archivo\n",
    "    base_name=$(basename \"$bam_file\" -noDups.bam)\n",
    "    \n",
    "    # Definir el archivo de salida para los datos de recalibraci√≥n\n",
    "    recal_data=\"${output_dir}/${base_name}-rec_bases\"\n",
    "    \n",
    "    # Recalibrar bases\n",
    "    gatk BaseRecalibrator \\\n",
    "        -R \"$reference\" \\\n",
    "        -I \"$bam_file\" \\\n",
    "        --known-sites \"$dbsnp\" \\\n",
    "        -O \"$recal_data\" \\\n",
    "        --use-original-qualities\n",
    "        \n",
    "    # Mensaje de confirmaci√≥n\n",
    "    echo \"Recalibraci√≥n de bases completada para $base_name.\"\n",
    "done\n",
    "\n",
    "######## Si no funcionan los pasos anteriores, intentar configurar de la siguiente manera:\n",
    "\n",
    "# ==== CONFIGURACI√ìN ====\n",
    "JAVA17_BIN=\"$HOME/java/jdk-17.0.10+7/bin/java\"\n",
    "GATK_JAR=\"$HOME/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/BWA_data/apps/gatk-4.6.1.0/gatk-package-4.6.1.0-local.jar\"\n",
    "\n",
    "bam_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/picard_exo/with_read_groups\"\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "dbsnp=\"/home/yordonez3/gatk-recursos/Homo_sapiens_assembly38.dbsnp138.vcf.gz\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/rec_bases\"\n",
    "\n",
    "# ==== VALIDACIONES ====\n",
    "if [[ ! -x \"$JAVA17_BIN\" ]]; then\n",
    "    echo \"‚ùå No se encontr√≥ Java 17 en: $JAVA17_BIN\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "if [[ ! -f \"$GATK_JAR\" ]]; then\n",
    "    echo \"‚ùå No se encontr√≥ el JAR de GATK en: $GATK_JAR\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# ==== RECALIBRACI√ìN DE BASES ====\n",
    "echo \"üöÄ Iniciando recalibraci√≥n de bases...\"\n",
    "\n",
    "for bam_file in \"$bam_dir\"/*_rg.bam; do\n",
    "    if [[ -f \"$bam_file\" ]]; then\n",
    "        base_name=$(basename \"$bam_file\" .bam)\n",
    "        recal_table=\"${output_dir}/${base_name}_recal_data.table\"\n",
    "\n",
    "        echo \"‚û°Ô∏è  Procesando: $base_name\"\n",
    "\n",
    "        \"$JAVA17_BIN\" -jar \"$GATK_JAR\" BaseRecalibrator \\\n",
    "            -R \"$reference\" \\\n",
    "            -I \"$bam_file\" \\\n",
    "            --known-sites \"$dbsnp\" \\\n",
    "            -O \"$recal_table\" \\\n",
    "            --use-original-qualities\n",
    "\n",
    "        echo \"‚úÖ Recalibraci√≥n completada: $recal_table\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"üéâ Proceso de recalibraci√≥n de bases finalizado.\"\n",
    "\n",
    "################################## RECALIBRAR MUESTRAS FALTANTES ############################################\n",
    "#!/bin/bash\n",
    "\n",
    "# ======= VARIABLES =======\n",
    "bam_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/picard_exo/with_read_groups\"\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "dbsnp=\"/home/yordonez3/bioconda3/gatk/Homo_sapiens_assembly38.dbsnp138.vcf\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/rec_bases\"\n",
    "gatk_path=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/BWA_data/apps/gatk-4.6.1.0\"\n",
    "\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "export PATH=\"$gatk_path:$PATH\"\n",
    "\n",
    "# ======= PROCESAMIENTO =======\n",
    "echo \"üöÄ Iniciando recalibraci√≥n de bases con GATK...\"\n",
    "\n",
    "for bam_file in \"$bam_dir\"/*_rg.bam; do\n",
    "  sample=$(basename \"$bam_file\" .bam)\n",
    "  \n",
    "  # Archivos de salida\n",
    "  table=\"$output_dir/${sample}_recal_data.table\"\n",
    "  out_bam=\"$output_dir/${sample}_recal.bam\"\n",
    "\n",
    "  # Saltar si ya existe\n",
    "  if [[ -f \"$out_bam\" ]]; then\n",
    "    echo \"‚è© Ya procesado: $sample (omitido)\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  echo \"üìå Recalibrando: $sample\"\n",
    "\n",
    "  # Paso 1: BaseRecalibrator\n",
    "  gatk BaseRecalibrator \\\n",
    "    -I \"$bam_file\" \\\n",
    "    -R \"$reference\" \\\n",
    "    --known-sites \"$dbsnp\" \\\n",
    "    -O \"$table\" \\\n",
    "    || { echo \"‚ùå Error en BaseRecalibrator: $sample\"; continue; }\n",
    "\n",
    "  # Paso 2: ApplyBQSR\n",
    "  gatk ApplyBQSR \\\n",
    "    -R \"$reference\" \\\n",
    "    -I \"$bam_file\" \\\n",
    "    --bqsr-recal-file \"$table\" \\\n",
    "    -O \"$out_bam\" \\\n",
    "    || { echo \"‚ùå Error en ApplyBQSR: $sample\"; continue; }\n",
    "\n",
    "  echo \"‚úÖ Recalibraci√≥n completada: $out_bam\"\n",
    "done\n",
    "\n",
    "echo \"üéâ Todos los BAM han sido recalibrados y est√°n en: $output_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecd4b0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3211606965.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    for recal_table in \"$recal_dir\"/*_recal_data.table; do\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "### GENERAR BAM RECALIBRADO\n",
    "\n",
    "# Rutas base\n",
    "\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/VARIANTES\"\n",
    "recal_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/VARIANTES\"\n",
    "\n",
    "# Iterar sobre cada archivo .table\n",
    "for recal_table in \"$recal_dir\"/*_recal_data.table; do\n",
    "    # Extraer nombre base correctamente (sin _recal_data.table)\n",
    "    base_name=$(basename \"$recal_table\" _recal_data.table)\n",
    "\n",
    "    bam_file=\"$bam_dir/${base_name}.bam\"\n",
    "    output_bam=\"${output_dir}/${base_name}-BQSR.bam\"\n",
    "\n",
    "    # Verificar existencia del BAM original\n",
    "    if [ ! -f \"$bam_file\" ]; then\n",
    "        echo \"‚ö†Ô∏è No se encontr√≥ el archivo BAM esperado: $bam_file\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    # Saltar si el BAM recalibrado ya existe\n",
    "    if [ -f \"$output_bam\" ]; then\n",
    "        echo \"‚è≠Ô∏è BAM recalibrado ya existe para $base_name, se salta.\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    echo \"üöÄ Recalibrando: $bam_file\"\n",
    "    \n",
    "    gatk ApplyBQSR \\\n",
    "        -I \"$bam_file\" \\\n",
    "        -R \"$reference\" \\\n",
    "        --bqsr-recal-file \"$recal_table\" \\\n",
    "        -O \"$output_bam\"\n",
    "\n",
    "    echo \"‚úÖ Recalibraci√≥n completada para $base_name\"\n",
    "done\n",
    "\n",
    "echo \"üéâ Todos los BAM posibles han sido procesados.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf50a0-ee90-4e77-bea6-64e0b6027373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intentar una soluci√≥n m√°s limpia cuando JAVA no funciona\n",
    "\n",
    "#Primero, limpia las variables de entorno que ya configuraste:\n",
    "\n",
    "unset JAVA_HOME\n",
    "unset JRE_HOME\n",
    "unset _JAVA_OPTIONS\n",
    "unset CLASSPATH\n",
    "\n",
    "#Intenta descargar una versi√≥n precompilada de OpenJDK que sea compatible con tu sistema:\n",
    "\n",
    "mkdir -p ~/java\n",
    "cd ~/java\n",
    "wget https://download.java.net/java/GA/jdk17.0.2/dfd4a8d0985749f896bed50d7138ee7f/8/GPL/openjdk-17.0.2_linux-x64_bin.tar.gz\n",
    "tar -xzf openjdk-17.0.2_linux-x64_bin.tar.gz\n",
    "\n",
    "#Configura las variables de entorno asegur√°ndote de que no haya conflicto con Miniconda:\n",
    "\n",
    "echo 'export JAVA_HOME=$HOME/java/jdk-17.0.2' >> ~/.bashrc\n",
    "echo 'export PATH=$JAVA_HOME/bin:$PATH' >> ~/.bashrc\n",
    "\n",
    "#Para evitar el problema con las bibliotecas compartidas, a√±ade expl√≠citamente:\n",
    "\n",
    "echo 'export LD_LIBRARY_PATH=$JAVA_HOME/lib:$JAVA_HOME/lib/server:$LD_LIBRARY_PATH' >> ~/.bashrc\n",
    "\n",
    "#Aplica los cambios:\n",
    "\n",
    "source ~/.bashrc\n",
    "\n",
    "#Verifica la instalaci√≥n:\n",
    "\n",
    "java -version\n",
    "Si el problema persiste, podr√≠a ser necesario desactivar temporalmente Miniconda mientras usas Java:\n",
    "# Antes de usar Java\n",
    "PATH=$(echo $PATH | sed 's|/home/yordonez3/miniconda3/bin:||')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c579f-638a-4152-a942-a3282fcd9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### DESPUES DE ESTE PASO HAY DOS OPCIONES, \n",
    "#### SE CONTINUA EL LLAMADO DE VARIANTES SOMATICAS CON MUTEC2 O LLAMADO DE VARIANTES GERMINALES CON HAPLOTYPECALLER (ANCESTRIA GENETICA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a34d6-418c-4c68-b006-adefdb9e3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### VARIANTES SOMATICAS ######################################################\n",
    "################################################  MUTEC2 ######################################################\n",
    "\n",
    "## 1 ## LLAMADO DE VARIANTES (cuando solo se tiene tumor)\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/variantes\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutec2\"\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38880a-d1f4-4a14-8ef6-ff961ffddf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################LLAMADO DE VARIANTES\n",
    "\n",
    "# üìÅ Crear el directorio de salida si no existe\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# üìÑ Obtener nombres base de las muestras\n",
    "samples=($(ls \"$input_dir\"/*-BQSR.bam | xargs -n 1 basename | sed 's/-BQSR.bam//'))\n",
    "\n",
    "# üîÅ Procesar cada muestra individualmente\n",
    "for sample_name in \"${samples[@]}\"; do\n",
    "    input_bam=\"${input_dir}/${sample_name}-BQSR.bam\"\n",
    "    output_vcf=\"${output_dir}/${sample_name}.vcf.gz\"\n",
    "\n",
    "    echo \"üöÄ Ejecutando Mutect2 para la muestra: $sample_name\"\n",
    "\n",
    "    if gatk Mutect2 \\\n",
    "        -R \"$reference\" \\\n",
    "        -I \"$input_bam\" \\\n",
    "        -O \"$output_vcf\" \\\n",
    "        --native-pair-hmm-threads 60 \\\n",
    "        -L chr1 -L chr2 -L chr3 -L chr4 -L chr5 \\\n",
    "        -L chr6 -L chr7 -L chr8 -L chr9 -L chr10 \\\n",
    "        -L chr11 -L chr12 -L chr13 -L chr14 -L chr15 \\\n",
    "        -L chr16 -L chr17 -L chr18 -L chr19 -L chr20 \\\n",
    "        -L chr21 -L chr22 -L chrX -L chrY; then\n",
    "\n",
    "        echo \"‚úÖ Mutect2 completado correctamente para $sample_name\"\n",
    "    else\n",
    "        echo \"‚ùå ERROR: Fall√≥ Mutect2 para $sample_name\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"üéØ Todas las muestras han sido procesadas.\"\n",
    "\n",
    "## Si se para la corrida:\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/variantes\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutec2\"\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "# Obtener los nombres de las muestras basados en los archivos BAM recalibrados\n",
    "samples=($(ls \"${input_dir}\"/*-BQSR.bam | xargs -n 1 basename | sed 's/-BQSR.bam//'))\n",
    "\n",
    "# Loop para procesar cada muestra con Mutect2 (SI SE TUVO QUE HACER)\n",
    "for sample_name in \"${samples[@]}\"; do\n",
    "    input_bam=\"${input_dir}/${sample_name}-BQSR.bam\"\n",
    "    output_vcf=\"${output_dir}/${sample_name}.vcf.gz\"\n",
    "    output_tbi=\"${output_vcf}.tbi\"\n",
    "    output_stats=\"${output_vcf}.stats\"\n",
    "\n",
    "    # Comprobar si alguno de los archivos de salida YA EXISTE:\n",
    "    if [ -f \"$output_vcf\" ] && [ -f \"$output_tbi\" ] && [ -f \"$output_stats\" ]; then\n",
    "        echo \"Los archivos de salida para la muestra $sample_name ya existen. Saltando.\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    # Ejecutar Mutect2 para llamada de variantes solo tumor, especificando cromosomas\n",
    "    gatk Mutect2 \\\n",
    "        -R \"$reference\" \\\n",
    "        -I \"$input_bam\" \\\n",
    "        -O \"$output_vcf\" \\\n",
    "        --native-pair-hmm-threads 60 \\\n",
    "        -L chr1 -L chr2 -L chr3 -L chr4 -L chr5 \\\n",
    "        -L chr6 -L chr7 -L chr8 -L chr9 -L chr10 \\\n",
    "        -L chr11 -L chr12 -L chr13 -L chr14 -L chr15 \\\n",
    "        -L chr16 -L chr17 -L chr18 -L chr19 -L chr20 \\\n",
    "        -L chr21 -L chr22 -L chrX -L chrY\n",
    "\n",
    "    echo \"Mutect2 completado para la muestra $sample_name\"\n",
    "done\n",
    "\n",
    "### Para correr cerrando el pc\n",
    "\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/variantes\"\n",
    "output_dir=\"/home/yordonez3/concatenated_fastq/concatenated_all_fastq/mutec2\"\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/GRCh38_Gencode31/hg38.fa\"\n",
    "\n",
    "# Ejecutar en segundo plano con nohup y redirigir salida a un log\n",
    "nohup bash -c '\n",
    "samples=($(ls '\"${input_dir}\"'/*-BQSR.bam | xargs -n 1 basename | sed \"s/-BQSR.bam//\"))\n",
    "\n",
    "for sample_name in \"${samples[@]}\"; do\n",
    "    input_bam=\"'\"${input_dir}\"'/${sample_name}-BQSR.bam\"\n",
    "    output_vcf=\"'\"${output_dir}\"'/${sample_name}.vcf.gz\"\n",
    "\n",
    "    # Ejecutar Mutect2\n",
    "    gatk Mutect2 \\\n",
    "        -R \"'\"${reference}\"'\" \\\n",
    "        -I \"$input_bam\" \\\n",
    "        -O \"$output_vcf\" \\\n",
    "        --native-pair-hmm-threads 60 \\\n",
    "        -L chr1 -L chr2 -L chr3 -L chr4 -L chr5 \\\n",
    "        -L chr6 -L chr7 -L chr8 -L chr9 -L chr10 \\\n",
    "        -L chr11 -L chr12 -L chr13 -L chr14 -L chr15 \\\n",
    "        -L chr16 -L chr17 -L chr18 -L chr19 -L chr20 \\\n",
    "        -L chr21 -L chr22 -L chrX -L chrY\n",
    "\n",
    "    echo \"Mutect2 completado para la muestra $sample_name\"\n",
    "done\n",
    "' > mutect2_llamado_variantes.log 2>&1 &\n",
    "\n",
    "# Verificar el estado del proceso\n",
    "ps aux | grep gatk\n",
    "\n",
    "# Confirmar que el proceso est√° activo\n",
    "tail -f mutect2_llamado_variantes.log  # Para salir usa ctrl+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0e8ba3-dc04-4509-a294-9ba70690788a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1893628413.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    mkdir -p \"$filtered_output_dir\"\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## 2 ##  FILTRADO DE VARIANTES MUTEC2\n",
    "\n",
    "### Para conocer los parametros de filtro:\n",
    "# https://github.com/broadinstitute/gatk/blob/master/docs/mutect/mutect.pdf\n",
    "\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutec2\"\n",
    "filtered_output_dir=\"home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutect2_filtered\"\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "# Crear el directorio de salida si no existe\n",
    "mkdir -p \"$filtered_output_dir\"\n",
    "\n",
    "# Obtener los nombres de las muestras basados en los archivos VCF sin filtrar de Mutect2\n",
    "samples=($(ls \"${input_dir}\"/*.vcf.gz | xargs -n 1 basename | sed 's/.vcf.gz//'))\n",
    "\n",
    "# Loop para procesar cada muestra con FilterMutectCalls\n",
    "for sample_name in \"${samples[@]}\"; do\n",
    "    unfiltered_vcf=\"${input_dir}/${sample_name}.vcf\"\n",
    "    filtered_vcf=\"${filtered_output_dir}/${sample_name}_filtered.vcf\"\n",
    "\n",
    "    # Ejecutar FilterMutectCalls\n",
    "    gatk FilterMutectCalls \\\n",
    "        -V \"$unfiltered_vcf\" \\\n",
    "        -R \"$reference\" \\\n",
    "        -O \"$filtered_vcf\"\n",
    "\n",
    "    echo \"FilterMutectCalls completado para la muestra $sample_name\"\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "## especificar .gz\n",
    "\n",
    "# Definir rutas\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutec2\"\n",
    "filtered_output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutect2_filtered\"\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "# Crear el directorio de salida si no existe\n",
    "mkdir -p \"$filtered_output_dir\"\n",
    "\n",
    "# Obtener los nombres de las muestras basados en los archivos .vcf.gz\n",
    "samples=($(ls \"${input_dir}\"/*.vcf.gz | xargs -n 1 basename | sed 's/.vcf.gz//'))\n",
    "\n",
    "# Loop para procesar cada muestra con FilterMutectCalls\n",
    "for sample_name in \"${samples[@]}\"; do\n",
    "    unfiltered_vcf=\"${input_dir}/${sample_name}.vcf.gz\"\n",
    "    filtered_vcf=\"${filtered_output_dir}/${sample_name}_filtered.vcf\"\n",
    "\n",
    "    # Verificar que el archivo exista antes de procesar\n",
    "    if [[ -f \"$unfiltered_vcf\" ]]; then\n",
    "        gatk FilterMutectCalls \\\n",
    "            -V \"$unfiltered_vcf\" \\\n",
    "            -R \"$reference\" \\\n",
    "            -O \"$filtered_vcf\"\n",
    "\n",
    "        echo \"‚úÖ FilterMutectCalls completado para la muestra $sample_name\"\n",
    "    else\n",
    "        echo \"‚ö†Ô∏è  Archivo no encontrado: $unfiltered_vcf\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NORMALIZACION ANTES DEL MERGE\n",
    "\n",
    "## NORMALIZACION ANTES DEL MERGE\n",
    "\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutect2_filtered\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutect2_normalized\"\n",
    "\n",
    "# Crear directorio de salida si no existe\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# Iterar sobre todos los archivos VCF\n",
    "for file in \"$input_dir\"/*.vcf; do\n",
    "    # Nombre base del archivo\n",
    "    filename=$(basename \"$file\")\n",
    "\n",
    "    # Normalizar el archivo y guardarlo en el directorio de salida\n",
    "    echo \"Normalizando $filename...\"\n",
    "    bcftools norm -m -any -O z -o \"$output_dir/${filename}.gz\" \"$file\"\n",
    "\n",
    "    echo \"$filename normalizado.\"\n",
    "done\n",
    "\n",
    "\n",
    "## Para correrlo con el pc cerrado\n",
    "input_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutect2_filtered\"\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/mutect2_normalized\"\n",
    "\n",
    "nohup bash -c '\n",
    "# Crear directorio de salida si no existe\n",
    "mkdir -p \"'\"${output_dir}\"'\"\n",
    "\n",
    "# Obtener lista de archivos VCF\n",
    "samples=($(ls \"'\"${input_dir}\"'\"/*.vcf | xargs -n 1 basename))\n",
    "\n",
    "# Iterar sobre los archivos y normalizarlos\n",
    "for filename in \"${samples[@]}\"; do\n",
    "    input_vcf=\"'\"${input_dir}\"'/${filename}\"\n",
    "    output_vcf=\"'\"${output_dir}\"'/${filename}\"\n",
    "\n",
    "    echo \"Normalizando $filename...\"\n",
    "    \n",
    "    bcftools norm -m -any -O z -o \"$output_vcf\" \"$input_vcf\"\n",
    "\n",
    "    echo \"$filename normalizado.\"\n",
    "done\n",
    "' > normalizacion_vcf.log 2>&1 &\n",
    "\n",
    "# Verificar el estado del proceso\n",
    "ps aux | grep bcftools\n",
    "\n",
    "# Confirmar que el proceso est√° activo\n",
    "tail -f normalizacion_vcf.log\n",
    "\n",
    "\n",
    "\n",
    "##Ver que los archivos mantengan ID ,,\n",
    "bcftools view -h /home/wovalle3/Samples/total_samples_pool/EXOMA/mutect2_filtered/8T_439645_filtered.vcf.gz | grep \"#CHROM\"\n",
    "\n",
    "bcftools query -l /home/wovalle3/Samples/total_samples_pool/EXOMA/mutect2_filtered/8T_439645_filtered.vcf.gz\n",
    "\n",
    "\n",
    "# Ver encabezado de los archivos normalizados para verificar que quedaron bien\n",
    "for file in \"$output_dir\"/*.vcf.gz; do\n",
    "    bcftools view -h \"$file\"\n",
    "done\n",
    "\n",
    "\n",
    "## Generar el index para poder procesarlos \n",
    "for vcf in *.vcf.gz; do\n",
    "    bcftools index \"$vcf\"\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ## ## ## ## ## ## ## ####  HACER MERGE DE LAS MUESTRAS GENERAR UN SOLO ARCHIVO\n",
    "## REVISAR SCRIPT CARLOS\n",
    "\n",
    "bcftools merge -m all -O z -o combined_samples.vcf.gz *.vcf.gz\n",
    "\n",
    "\n",
    "## verificar los enxabezados\n",
    "bcftools view -h combined_samples.vcf.gz | grep \"#CHROM\"\n",
    "## lista de muestras\n",
    "bcftools query -l combined_samples.vcf.gz\n",
    "## confirmar que hay variantes en el archivo \n",
    "bcftools view combined_samples.vcf.gz | grep -v \"^#\" | head -n 10\n",
    "\n",
    "\n",
    "## confirmar el numero de variantes \n",
    "bcftools view -H combined_samples.vcf.gz | wc -l\n",
    "# 75.998.047\n",
    "\n",
    "bcftools view combined_samples.vcf.gz | grep -v '^#' | wc -l\n",
    "# 75.998.047\n",
    "\n",
    "/home/wovalle3/Samples/total_samples_pool/EXOMA/mutect2_filtered/normalized\n",
    "\n",
    "\n",
    "### Hacer un filtro adicional de calidad\n",
    "bcftools filter -e \"QUAL<30 || INFO/DP<10\" combined_samples.vcf.gz -o combined_samples_filtered.vcf.gz\n",
    "\n",
    "bcftools view combined_samples_filtered.vcf.gz | grep -v '^#' | wc -l\n",
    "# 8.955.368\n",
    "\n",
    "\n",
    "### Filtrar el archivo VCF para genes espec√≠ficos (KRAS, APC, BRAF, TP53)\n",
    "zgrep -E 'KRAS|APC|BRAF|TP53' combined_samples_filtered.vcf.gz > filtered_genes_variants.vcf.gz\n",
    "\n",
    "## Extraer las columnas con los genotipos de los pacientes\n",
    "bcftools view filtered_genes_variants.vcf.gz | cut -f1-9,10- > filtered_genes_variants_with_samples.vcf.gz\n",
    "\n",
    "\n",
    "\n",
    "##Analizar por paciente\n",
    "grep '118T_444772' filtered_genes_variants_with_samples.vcf > patient_118T_444772_KRAS_mutations.vcf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f18a3b6-3b2f-4ff3-9fe0-1e19e4eba81c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (3183019685.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    wget http://www.openbioinformatics.org/annovar/download/0wgxR2rIVP/annovar.latest.tar.gz\u001b[0m\n\u001b[1;37m                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "### ANOTACION CON ANNOVAR\n",
    "wget http://www.openbioinformatics.org/annovar/download/0wgxR2rIVP/annovar.latest.tar.gz\n",
    "tar -zxvf annovar.latest.tar.gz\n",
    "\n",
    "## descargar bases de datos\n",
    "perl ./annotate_variation.pl -downdb -buildver hg38 -webfrom annovar refGene /home/wovalle3/annovar/humandb/\n",
    "perl ./annotate_variation.pl -downdb -buildver hg38 -webfrom annovar refGeneWithVer /home/wovalle3/annovar/humandb/\n",
    "perl ./annotate_variation.pl -downdb -buildver hg38 -webfrom annovar clinvar_20240917 /home/wovalle3/annovar/humandb/\n",
    "perl ./annotate_variation.pl -downdb -buildver hg38 -webfrom annovar dbnsfp35a /home/wovalle3/annovar/humandb/\n",
    "perl ./annotate_variation.pl -downdb -buildver hg38 -webfrom annovar exac03 /home/wovalle3/annovar/humandb/\n",
    "#perl ./annotate_variation.pl -downdb -buildver hg38 cosmic64 /home/wovalle3/annovar/humandb/\n",
    "\n",
    "\n",
    "\n",
    "## Anotar variantes\n",
    "## Primero convertir archivo VCF a formato annovar\n",
    "perl /home/wovalle3/annovar/convert2annovar.pl -format vcf4 combined_samples_filtered.vcf.gz > annotated_variants2.avinput\n",
    "\n",
    "\n",
    "## Correr anotaciones \n",
    "perl /home/wovalle3/annovar/table_annovar.pl annotated_variants.avinput \\\n",
    "/home/wovalle3/annovar/humandb/ -buildver hg38 \\\n",
    "-out annotated_variants \\\n",
    "-protocol refGeneWithVer,clinvar_20240917,dbnsfp35a,exac03 \\\n",
    "-operation g,f,f,f \\\n",
    "-csvout \\\n",
    "-nopolish \\\n",
    "-remove\n",
    "\n",
    "\n",
    "## Con este se transforma de una vez y se anota dejando archivos .txt y vfc\n",
    "perl /home/wovalle3/annovar/table_annovar.pl /home/wovalle3/Samples/total_samples_pool/EXOMA/mutect2_filtered/normalized/combined_samples_filtered.vcf.gz \\\n",
    "/home/wovalle3/annovar/humandb/ -buildver hg38 \\\n",
    "-out annotated_variants \\\n",
    "-protocol refGeneWithVer,clinvar_20240917,dbnsfp35a,exac03 \\\n",
    "-operation g,f,f,f \\\n",
    "-remove \\\n",
    "--vcfinput\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "multiqc /home/wovalle3/Samples/total_samples_pool/EXOMA/mutect2_filtered/normalized \\\n",
    "/home/wovalle3/Samples/total_samples_pool/EXOMA/snpeff \\\n",
    "/home/wovalle3/Samples/total_samples_pool/EXOMA/annovar \\\n",
    "-o /home/wovalle3/Samples/total_samples_pool/EXOMA/MQCANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c9a01-7c3a-4bf7-9045-a9a450461b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANOTACI√ìN DE VARIANTES CON SNPEFF\n",
    "\n",
    "# El archivo `annotated_variants.vcf` generado por SnpEff contiene informaci√≥n adicional sobre cada variante. \n",
    "# Puedes clasificar las mutaciones seg√∫n el tipo, impacto funcional, etc.\n",
    "\n",
    "# Anotaci√≥n general:\n",
    "# java -jar /home/wovalle3/snpEff/snpEff.jar ann -c /home/wovalle3/snpEff/snpEff.config -v hg38 6T_439643_filtered.vcf.gz > annotated_variants.vcf\n",
    "\n",
    "# Anotaci√≥n de efectos relacionados con c√°ncer:\n",
    "java -jar /home/wovalle3/snpEff/snpEff.jar eff -cancer -csvStats stats.csv -v hg38 6T_439643_filtered.vcf.gz > annotated_variants2.vcf\n",
    "\n",
    "# Bucle para procesar m√∫ltiples muestras\n",
    "input_dir=\"/home/wovalle3/Samples/total_samples_pool/EXOMA/mutect2_filtered\"\n",
    "output_dir=\"/home/wovalle3/Samples/total_samples_pool/EXOMA/snpeff\"\n",
    "\n",
    "# Buscar archivos .vcf.gz y procesarlos\n",
    "for vcf_file in ${input_dir}/*_filtered.vcf.gz; do\n",
    "    sample_name=$(basename \"$vcf_file\" .vcf.gz)\n",
    "    output_vcf=\"${output_dir}/${sample_name}_annotated.vcf\"\n",
    "\n",
    "    java -jar /home/wovalle3/snpEff/snpEff.jar eff -cancer -csvStats \"${output_dir}/${sample_name}_stats.csv\" -v hg38 \"$vcf_file\" > \"$output_vcf\"\n",
    "\n",
    "    echo \"Anotaci√≥n completada para la muestra: $sample_name\"\n",
    "done\n",
    "\n",
    "echo \"Anotaci√≥n de variantes para todas las muestras completada.\"\n",
    "\n",
    "\n",
    "#### Si de mutect2 se logra unir el archivo correr entonces:\n",
    "java -jar /home/wovalle3/snpEff/snpEff.jar eff -cancer -csvStats stats.csv -v hg38 combined_samples.vcf.gz > /home/wovalle3/Samples/total_samples_pool/EXOMA/snpeff/annotated_variants_all.vcf\n",
    "\n",
    "\n",
    "\n",
    "### ANALISIS DE ARCHIVOS ANOTADOS\n",
    "\n",
    "# MultiQC para resumen global por muestra\n",
    "# Filtrar mutaciones de inter√©s como KRAS\n",
    "grep \"KRAS\" 8T_439645_filtered_annotated.vcf\n",
    "grep \"KRAS\" 8T_439645_filtered_annotated.vcf | wc -l\n",
    "\n",
    "# Ver todas las variantes con impacto HIGH\n",
    "grep -i \"HIGH\" 8T_439645_filtered_annotated.vcf\n",
    "grep -i \"HIGH\" 8T_439645_filtered_annotated.vcf | wc -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacff4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONVERTIR VCF A FORMATO TABULAR\n",
    "\n",
    "\n",
    "vcf_dir=\"/home/wovalle3/Samples/total_samples_pool/EXOMA/snpeff\"\n",
    "output_dir=\"/home/wovalle3/Samples/total_samples_pool/EXOMA/snpeff/fil_KRAS\"\n",
    "\n",
    "for vcf_file in \"$vcf_dir\"/*.vcf; do\n",
    "    base_name=$(basename \"$vcf_file\" .vcf)\n",
    "    gatk VariantsToTable \\\n",
    "        -V \"$vcf_file\" \\\n",
    "        -F CHROM -F POS -F ID -F REF -F ALT -F QUAL -F FILTER -F AS -F ANN -F GENN \\\n",
    "        -O \"$output_dir/$base_name.ann.txt\"\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "## Filtrar por mutaciones KRAS\n",
    "output_dir=\"/home/wovalle3/Samples/total_samples_pool/EXOMA/snpeff/fil_KRAS\"\n",
    "filtered_dir=\"/home/wovalle3/Samples/total_samples_pool/EXOMA/snpeff/fil_KRAS\"\n",
    "\n",
    "for file in \"$output_dir\"/*.ann.txt; do\n",
    "    base_name=$(basename \"$file\" .ann.txt)\n",
    "    grep -i \"KRAS\" \"$file\" > \"$filtered_dir/$base_name.KRAS_filtered.txt\"\n",
    "done\n",
    "\n",
    "# Contar las mutaciones de KRAS por muestra\n",
    "for file in \"$filtered_dir\"/*KRAS_filtered.txt; do\n",
    "    echo \"$file: $(wc -l < \"$file\") l√≠neas\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce32bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARA PODER REALIZAR ANALISIS POSTERIORES CON ANNOVAR O MUTSIG ES NECESARIO COMPRIMIR EN UN SOLO ARCHIVO LOS VCF\n",
    "\n",
    "\n",
    "## Comprimir los archivos que salen de snpEff\n",
    "\n",
    "for file in *.vcf; do\n",
    "    bgzip -c \"$file\" > \"${file}.gz\"\n",
    "done\n",
    "\n",
    "# Crear un √≠ndice\n",
    "for file in *.vcf.gz; do\n",
    "    tabix -p vcf \"$file\"\n",
    "done\n",
    "\n",
    "## Fusionar archivos\n",
    "\n",
    "bcftools merge -o combined.vcf -O v *.vcf.gz\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### UNA VEZ SE HAGA LA ANOTACION POR ANNOVAR o SNPEFF, SE PROCEDE A USAR LA LIBRERIA EN R MAFTOOLS PARA EL ANALISIS\n",
    "\n",
    "\n",
    "## Convertir VCF anotado a MAF para poder usar libreria MAFTOOLS\n",
    "\n",
    "##Previamente preparar objeto VEP\n",
    "conda update -y -n base -c defaults conda\n",
    "conda config --set solver libmamba\n",
    "conda create -y -n vep && conda activate vep\n",
    "conda install -y -c conda-forge -c bioconda -c defaults ensembl-vep==112.0 htslib==1.20 bcftools==1.20 samtools==1.20 ucsc-liftover==447\n",
    "\n",
    "mkdir -p $HOME/.vep/homo_sapiens/112_GRCh38/\n",
    "rsync -avr --progress rsync://ftp.ensembl.org/ensembl/pub/release-112/variation/indexed_vep_cache/homo_sapiens_vep_112_GRCh38.tar.gz $HOME/.vep/\n",
    "tar -zxf $HOME/.vep/homo_sapiens_vep_112_GRCh38.tar.gz -C $HOME/.vep/\n",
    "rsync -avr --progress rsync://ftp.ensembl.org/ensembl/pub/release-112/fasta/homo_sapiens/dna_index/ $HOME/.vep/homo_sapiens/112_GRCh38/\n",
    "vep --version\n",
    "\n",
    "\n",
    "conda activate vep\n",
    "## Correr vcf2maf\n",
    "/home/wovalle3/miniconda3/envs/vep/bin/vcf2maf.pl \\\n",
    "--input-vcf /home/wovalle3/Samples/total_samples_pool/EXOMA/annovar/annotated_variants.hg38_multianno.vcf \\\n",
    "--output-maf /home/wovalle3/Samples/total_samples_pool/EXOMA/annovar/annotated_variants.hg38_multianno.maf \\\n",
    "--ref-fasta /home/wovalle3/Samples/GRCh38_Gencode31/hg38.fa \\\n",
    "--vep-path /home/wovalle3/miniconda3/envs/vep/bin \\\n",
    "--vep-data /home/wovalle3/.vep \\\n",
    "--vep-forks 40\n",
    "\n",
    "\n",
    "## Probando primero con una sola muestra\n",
    "/home/wovalle3/miniconda3/envs/vep/bin/vcf2maf.pl \\\n",
    "--input-vcf 8T_439645_filtered_annotated.vcf \\\n",
    "--output-maf 8T_439645_filtered_annotated.maf \\\n",
    "--ref-fasta /home/wovalle3/Samples/GRCh38_Gencode31/hg38.fa \\\n",
    "--vep-path /home/wovalle3/miniconda3/envs/vep/bin \\\n",
    "--vep-data /home/wovalle3/.vep \\\n",
    "--vep-forks 10 \\\n",
    "--species homo_sapiens \\\n",
    "--ncbi-build GRCh38\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### CONVERTIR A .MAF EN R\n",
    "library(maftools)\n",
    "\n",
    "\n",
    "# Cargar el archivo de variantes anotadas de ANNOVAR\n",
    "getwd()\n",
    "setwd(\"/Users/wen/Library/CloudStorage/OneDrive-InstitutoNacionaldeCancerologiÃÅa/DOCTORADO/TESIS/RNA_seq_todas/Exoma_Ann\")\n",
    "annovar_file <- \"annotated_variants.hg38_multianno.csv\"\n",
    "anno_data <- read.csv(annovar_file)\n",
    "\n",
    "library(dplyr)\n",
    "\n",
    "# Definir la ruta del archivo anotado por ANNOVAR\n",
    "annovar_file <- \"annotated_variants.hg38_multianno.csv\"\n",
    "anno_data <- read.csv(annovar_file)\n",
    "\n",
    "# Definir las columnas relevantes para el formato MAF\n",
    "maf_columns <- c(\n",
    "  \"Chr\", \"Start\", \"End\", \"Ref\", \"Alt\", \"Gene.refGeneWithVer\", \n",
    "  \"ExonicFunc.refGeneWithVer\", \"AAChange.refGeneWithVer\", \n",
    "  \"SIFT_pred\", \"Polyphen2_HDIV_pred\", \"CADD_raw\", \n",
    "  \"MutationTaster_pred\", \"CLNSIG\"\n",
    ")\n",
    "\n",
    "# Filtrar las columnas relevantes\n",
    "maf_df <- anno_data %>%\n",
    "  select(all_of(maf_columns)) %>%\n",
    "  rename(\n",
    "    Chromosome = Chr,\n",
    "    Start_Position = Start, \n",
    "    End_Position = End,\n",
    "    Reference_Allele = Ref, \n",
    "    Tumor_Seq_Allele2 = Alt,\n",
    "    Hugo_Symbol = Gene.refGeneWithVer,\n",
    "    Variant_Classification = ExonicFunc.refGeneWithVer,\n",
    "    HGVSp_Short = AAChange.refGeneWithVer,\n",
    "    SIFT_Prediction = SIFT_pred,\n",
    "    PolyPhen_Prediction = Polyphen2_HDIV_pred,\n",
    "    CADD_Score = CADD_raw,\n",
    "    MutationTaster_Prediction = MutationTaster_pred,\n",
    "    Clinical_Significance = CLNSIG\n",
    "  )\n",
    "\n",
    "\n",
    "# Lista de identificadores de muestras tumorales (ajustar seg√∫n tus datos)\n",
    "tumor_ids <- c(\"10T_439647\", \"27T_439648\", \"31T_439649\", \"3T_439641\", \"43T_439650\", \n",
    "               \"45T_439651\", \"48T_439652\", \"4T_439642\", \"53T_439654\", \"57T_439655\", \n",
    "               \"65T_439658\", \"66T_439659\", \"67T_439660\", \"68T_439661\", \"6T_439643\", \n",
    "               \"72T_439662\", \"7T_439644\", \"8T_439645\")\n",
    "\n",
    "# Comprobar la longitud de los identificadores de tumor\n",
    "length(tumor_ids)\n",
    "\n",
    "# Asignar los identificadores de tumor al DataFrame\n",
    "maf_df$Tumor_Sample_Barcode <- rep(tumor_ids, length.out = nrow(maf_df))\n",
    "\n",
    "# Crear la columna Variant_Type basado en la longitud de Ref y Alt\n",
    "maf_df <- maf_df %>%\n",
    "  mutate(Variant_Type = case_when(\n",
    "    nchar(Reference_Allele) == 1 & nchar(Tumor_Seq_Allele2) == 1 ~ \"SNP\",\n",
    "    nchar(Reference_Allele) < nchar(Tumor_Seq_Allele2) ~ \"INS\",\n",
    "    nchar(Reference_Allele) > nchar(Tumor_Seq_Allele2) ~ \"DEL\",\n",
    "    TRUE ~ NA_character_\n",
    "  ))\n",
    "\n",
    "# Funci√≥n para clasificar variantes seg√∫n el tipo de mutaci√≥n\n",
    "classify_variant <- function(x) {\n",
    "  if (x == \"synonymous SNV\") {\n",
    "    return(NA)\n",
    "  } else if (x == \"nonsynonymous SNV\") {\n",
    "    return(\"Missense_Mutation\")\n",
    "  } else if (x == \"nonframeshift deletion\") {\n",
    "    return(\"In_Frame_Del\")\n",
    "  } else if (x == \"frameshift deletion\") {\n",
    "    return(\"Frame_Shift_Del\")\n",
    "  } else if (x == \"nonframeshift insertion\") {\n",
    "    return(\"In_Frame_Ins\")\n",
    "  } else if (x == \"frameshift insertion\") {\n",
    "    return(\"Frame_Shift_Ins\")\n",
    "  } else if (x == \"stopgain\" || x == \"stoploss\") {\n",
    "    return(\"Nonsense_Mutation\")\n",
    "  } else if (x == \"startloss\") {\n",
    "    return(\"Nonsense_Mutation\")\n",
    "  } else if (x == \"unknown\") {\n",
    "    return(NA)\n",
    "  } else {\n",
    "    return(\"Splice_Site\")\n",
    "  }\n",
    "}\n",
    "\n",
    "# Aplicar la clasificaci√≥n de variantes\n",
    "maf_df$Variant_Classification <- sapply(maf_df$Variant_Classification, classify_variant)\n",
    "\n",
    "# Filtrar las filas donde la clasificaci√≥n de variante no es NA\n",
    "maf_df <- maf_df[!is.na(maf_df$Variant_Classification), ]\n",
    "\n",
    "# Reordenar las columnas seg√∫n el formato MAF\n",
    "maf_columns_order <- c(\n",
    "  \"Hugo_Symbol\", \"Chromosome\", \"Start_Position\", \"End_Position\",\n",
    "  \"Reference_Allele\", \"Tumor_Seq_Allele2\", \"Variant_Classification\",\n",
    "  \"HGVSp_Short\", \"Variant_Type\", \"Tumor_Sample_Barcode\",\n",
    "  \"SIFT_Prediction\", \"PolyPhen_Prediction\", \"CADD_Score\",\n",
    "  \"MutationTaster_Prediction\", \"Clinical_Significance\"\n",
    ")\n",
    "\n",
    "# Asegurarse de que las columnas que existen en maf_df est√©n en el orden adecuado\n",
    "maf_df <- maf_df %>%\n",
    "  select(all_of(maf_columns_order))\n",
    "head(maf_df)\n",
    "\n",
    "# Guardar el archivo en formato MAF (tab-separated)\n",
    "output_file <- \"output_maf_file.maf\"\n",
    "write.table(maf_df, file = output_file, sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE)\n",
    "\n",
    "\n",
    "\n",
    "install.packages(\"BiocManager\")\n",
    "\n",
    "BiocManager::install(\"maftools\")\n",
    "library(maftools)\n",
    "\n",
    "\n",
    "## Leer el .maf\n",
    "getwd()\n",
    "setwd(\"/home/wovalle3/Samples/total_samples_pool/EXOMA/mutect2_filtered/normalized\")\n",
    "maf_data <- read.maf(maf = \"output_maf_file.maf\", verbose = FALSE)\n",
    "\n",
    "\n",
    "## Analisis\n",
    "maf_summary(maf_data)\n",
    "## Primeras filas \n",
    "head(getSampleSummary(maf_data))\n",
    "getSampleSummary(maf_data)\n",
    "\n",
    "## Gene summary\n",
    "getGeneSummary(maf_data)\n",
    "\n",
    "## como coldata\n",
    "getFields(maf_data)\n",
    "\n",
    "\n",
    "\n",
    "## Graficos \n",
    "##  Plotting MAF summary.\n",
    "plotmafSummary(maf = maf_data, rmOutlier = TRUE, addStat = 'median', dashboard = TRUE, titvRaw = FALSE)\n",
    "\n",
    "mafbarplot(maf = maf_data, top = 10)\n",
    "\n",
    "## Oncoplots\n",
    "oncoplot(maf = maf_data, top = 10)\n",
    "\n",
    "\n",
    "laml.titv = titv(maf = maf_data, plot = FALSE, useSyn = TRUE)\n",
    "#plot titv summary\n",
    "plotTiTv(res = laml.titv)\n",
    "\n",
    "\n",
    "## Lollipop plots for amino acid changes\n",
    "#lollipop plot for DNMT3A, which is one of the most frequent mutated gene in Leukemia.\n",
    "lollipopPlot(\n",
    "  maf = maf_data,\n",
    "  gene = 'KRAS',\n",
    "  AACol = 'Protein_Change',\n",
    "  showMutationRate = TRUE,\n",
    "  labelPos = 882\n",
    ")\n",
    "\n",
    "\n",
    "### Plotting VAF (Variant Allele Frequencies)\n",
    "plotVaf(maf = maf_data, vafCol = 'i_TumorVAF_WU')\n",
    "\n",
    "\n",
    "# Generar el gr√°fico y guardarlo en un archivo PNG\n",
    "png(\"/home/wovalle3/Samples/total_samples_pool/EXOMA/plots/maf_summary.png\", width = 800, height = 600)\n",
    "plotmafSummary(maf_data)\n",
    "dev.off()  # Finaliza la escritura en el archivo PNG\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### para convertir archivo annovar a maf\n",
    "getwd()\n",
    "setwd(\"/home/wovalle3/Samples/total_samples_pool/EXOMA/mutect2_filtered/normalized\")\n",
    "\n",
    "annovar_file <- \"annotated_variants.hg38_multianno.csv\"\n",
    "annovar_file2 <- \"annotated_variants.refGene.variant_function\"\n",
    "\n",
    "\n",
    "maf_file <- annovarToMaf(annovar = annovar_file2,\n",
    "                         refBuild = \"hg38\",        # Especifica el genoma de referencia (puede ser \"hg38\" o \"hg19\")\n",
    "                         table = \"refGene\",        # Tabla de referencia (puede ser \"refGene\" o \"ensGene\")\n",
    "                         #header = TRUE,            # Si el archivo ANNOVAR tiene encabezado, ponlo en TRUE\n",
    "                         sep = \"\\t\",               # Separador de campos (tabulado por defecto)\n",
    "                         MAFobj = FALSE,           # Si FALSE, devuelve el archivo MAF como un data frame\n",
    "                         basename = \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230ba205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 68) (3964709590.py, line 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 68\u001b[0;36m\u001b[0m\n\u001b[0;31m    nohup bash -c \"\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 68)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################################ VARIANTES GERMINALES ######################################################\n",
    "################################################  HAPLOTYPECALLER ######################################################\n",
    "\n",
    "## LLAMADO DE VARIANTES GERMINALES\n",
    "\n",
    "mkdir -p \"gvcfs\"\n",
    "\n",
    "# Ruta al archivo de referencia\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "# Directorio donde est√°n los BAM con BQSR\n",
    "bam_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/VARIANTES\"\n",
    "\n",
    "# Directorio donde se guardar√°n los GVCF generados\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/VARIANTES/gvcfs\"\n",
    "\n",
    "# Archivo dbSNP\n",
    "dbsnp_file=\"/home/yordonez3/gatk-recursos/Homo_sapiens_assembly38.dbsnp138.vcf\"\n",
    "\n",
    "# Ruta al archivo GATK local\n",
    "gatk_jar=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/gatk-4.6.1.0/gatk-package-4.6.1.0-local.jar\"\n",
    "\n",
    "# N√∫mero de hilos a usar\n",
    "num_threads=14\n",
    "\n",
    "# Iterar sobre los BAM ya recalibrados\n",
    "for bam_file in \"$bam_dir\"/*-BQSR.bam; do\n",
    "  sample_name=$(basename \"$bam_file\" -BQSR.bam)\n",
    "  output_gvcf=\"$output_dir/gvcfs/${sample_name}.g.vcf.gz\"\n",
    "\n",
    "  # Verificar si ya existe el archivo .g.vcf.gz\n",
    "  if [[ -f \"$output_gvcf\" ]]; then\n",
    "    echo \"Archivo GVCF ya existe para $sample_name, se omite.\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  java -Xmx35g -jar \"$gatk_jar\" HaplotypeCaller \\\n",
    "    -R \"$reference\" \\\n",
    "    -I \"$bam_file\" \\\n",
    "    -O \"$output_gvcf\" \\\n",
    "    -ERC GVCF \\\n",
    "    --dbsnp \"$dbsnp_file\" \\\n",
    "    --native-pair-hmm-threads \"$num_threads\"\n",
    "\n",
    "  echo \"HaplotypeCaller completado para $sample_name.\"\n",
    "done\n",
    "\n",
    "## Cerrando el pc\n",
    "\n",
    "# Ruta al archivo de referencia\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "# Directorio donde est√°n los BAM con BQSR\n",
    "bam_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/BAM_rec\"\n",
    "\n",
    "# Directorio donde se guardar√°n los GVCF generados\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/variantes_germinales\"\n",
    "\n",
    "# Archivo dbSNP\n",
    "dbsnp_file=\"/home/yordonez3/gatk-recursos/Homo_sapiens_assembly38.dbsnp138.vcf\"\n",
    "\n",
    "# Ruta al archivo GATK local\n",
    "gatk_jar=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/gatk-4.6.1.0/gatk-package-4.6.1.0-local.jar\"\n",
    "\n",
    "num_threads=14\n",
    "\n",
    "mkdir -p \"$output_dir/gvcfs\"\n",
    "\n",
    "nohup bash -c \"\n",
    "for bam_file in $output_dir/*-BQSR.bam; do\n",
    "  sample_name=\\$(basename \\$bam_file -BQSR.bam)\n",
    "\n",
    "  java -Xmx35g -jar \"$gatk_jar\" HaplotypeCaller \\\n",
    "    -R \\\"$reference\\\" \\\n",
    "    -I \\\"\\$bam_file\\\" \\\n",
    "    -O \\\"$output_dir/gvcfs/\\${sample_name}.g.vcf.gz\\\" \\\n",
    "    -ERC GVCF \\\n",
    "    --dbsnp \\\"$dbsnp_file\\\" \\\n",
    "    --native-pair-hmm-threads \\\"$num_threads\\\"\n",
    "\n",
    "  echo \\\"HaplotypeCaller completado para \\$sample_name.\\\"\n",
    "done\n",
    "\" > \"$output_dir/llamado_de_variantes.log\" 2>&1 &\n",
    "\n",
    "#### Para verificar que los archivos vcf se generaron bien:\n",
    "\n",
    "##### Revisa todos los archivos .g.vcf.gz en el directorio actual\n",
    "for file in *.g.vcf.gz; do\n",
    "    echo \"üîç Verificando $file...\"\n",
    "\n",
    "    # Verifica si el archivo est√° bien comprimido con tabix\n",
    "    if tabix -p vcf \"$file\" 2>&1 | grep -q \"failed\"; then\n",
    "        echo \"‚ùå Archivo corrupto o mal comprimido: $file\"\n",
    "    else\n",
    "        echo \"‚úÖ Archivo v√°lido: $file\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "MODIFICADO:\n",
    "\n",
    "# Ruta al archivo de referencia\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "# Directorio donde est√°n los BAM con BQSR\n",
    "bam_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/variantes\"\n",
    "\n",
    "# Directorio donde se guardar√°n los GVCF generados\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/variantes_germinales\"\n",
    "\n",
    "# Archivo dbSNP\n",
    "dbsnp_file=\"/home/yordonez3/gatk-recursos/Homo_sapiens_assembly38.dbsnp138.vcf\"\n",
    "\n",
    "# Ruta al archivo GATK local\n",
    "gatk_jar=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/gatk-4.6.1.0/gatk-package-4.6.1.0-local.jar\"\n",
    "\n",
    "# Ejecutar todo el proceso con nohup para que siga corriendo en segundo plano\n",
    "nohup bash -c '\n",
    "\n",
    "# Iterar sobre los BAM ya recalibrados\n",
    "for bam_file in \"$bam_dir\"/*-BQSR.bam; do\n",
    "  sample_name=$(basename \"$bam_file\" -BQSR.bam)\n",
    "  output_vcf=\"$output_dir/gvcfs/${sample_name}.g.vcf.gz\"\n",
    "\n",
    "  # Verificar si el archivo .g.vcf.gz ya existe\n",
    "  if [ -f \"$output_vcf\" ]; then\n",
    "    echo \"El archivo $output_vcf ya existe, se omite el HaplotypeCaller para $sample_name.\" >> nohup.out\n",
    "    continue  # Salta al siguiente BAM si ya existe el archivo de salida\n",
    "  fi\n",
    "\n",
    "  # Ejecutar HaplotypeCaller si no existe el archivo de salida\n",
    "  java -Xmx35g -jar \"$gatk_jar\" HaplotypeCaller \\\n",
    "    -R \"$reference\" \\\n",
    "    -I \"$bam_file\" \\\n",
    "    -O \"$output_vcf\" \\\n",
    "    -ERC GVCF \\\n",
    "    --dbsnp \"$dbsnp_file\" \\\n",
    "    --native-pair-hmm-threads \"$num_threads\"\n",
    "\n",
    "  echo \"HaplotypeCaller completado para $sample_name.\" >> nohup.out\n",
    "done\n",
    "' &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENOMIC IMPORT\n",
    "\n",
    "# Ruta al genoma de referencia\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "# Directorio de salida\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/PANEL/gvcfs_panel\"\n",
    "\n",
    "# Ejecutable GATK (usando versi√≥n 4.2.2.0)\n",
    "gatk=\"$HOME/miniconda3/bin/java -jar /home/yordonez3/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar\"\n",
    "\n",
    "# Ruta a los archivos gVCF\n",
    "gvcf_dir=\"$output_dir/gvcfs_panel\"\n",
    "\n",
    "# Crear el directorio temporal si no existe\n",
    "tmp_dir=\"$gvcf_dir/tmp\"\n",
    "mkdir -p \"$tmp_dir\"\n",
    "\n",
    "# Verificar permisos de lectura y escritura\n",
    "if [ ! -r \"$tmp_dir\" ] || [ ! -w \"$tmp_dir\" ]; then\n",
    "  echo \"‚ùå Error: No tienes permisos de lectura/escritura en $tmp_dir\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "# Verificar si hay archivos g.vcf.gz\n",
    "gvcf_files=(\"$gvcf_dir\"/*.g.vcf.gz)\n",
    "if [ ! -e \"${gvcf_files[0]}\" ]; then\n",
    "  echo \"‚ö†Ô∏è No se encontraron archivos .g.vcf.gz en $gvcf_dir\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "# Mostrar cu√°ntas muestras encontr√≥\n",
    "echo \"üîé Se encontraron ${#gvcf_files[@]} muestras para importar.\"\n",
    "\n",
    "# Construir lista de inputs\n",
    "inputs=\"\"\n",
    "for file in \"${gvcf_files[@]}\"; do\n",
    "  inputs+=\" -V $file\"\n",
    "done\n",
    "\n",
    "# Lista de cromosomas\n",
    "chromosomes=(chr{1..22} chrX chrY)\n",
    "\n",
    "# Ejecutar por cada cromosoma solo si no se ha procesado\n",
    "for chr in \"${chromosomes[@]}\"; do\n",
    "  workspace_path=\"$output_dir/my_database_$chr\"\n",
    "  if [ -d \"$workspace_path\" ]; then\n",
    "    echo \"‚úÖ $chr ya fue procesado. Omitiendo...\"\n",
    "  else\n",
    "    echo \"üöÄ Procesando $chr ...\"\n",
    "    $gatk GenomicsDBImport \\\n",
    "      $inputs \\\n",
    "      --genomicsdb-workspace-path \"$workspace_path\" \\\n",
    "      --tmp-dir \"$tmp_dir\" \\\n",
    "      --intervals \"$chr\"\n",
    "\n",
    "    # Verifica si se cre√≥ correctamente\n",
    "    if [ $? -eq 0 ]; then\n",
    "      echo \"‚úÖ $chr importado correctamente.\"\n",
    "    else\n",
    "      echo \"‚ùå Error al importar $chr.\"\n",
    "    fi\n",
    "  fi\n",
    "done\n",
    "\n",
    "echo \"üéâ Proceso completo.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea86591-9fbc-407d-a1d7-09eecb1fa109",
   "metadata": {},
   "outputs": [],
   "source": [
    "####GENOMIC IMPORT PARA REVISAR ARVHIVOS\n",
    "#!/bin/bash\n",
    "\n",
    "# Ruta al genoma de referencia\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "# Directorio de salida\n",
    "output_dir=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/variantes_germinales\"\n",
    "\n",
    "# Ejecutable GATK (versi√≥n 4.2.2.0)\n",
    "gatk=\"$HOME/miniconda3/bin/java -jar /home/yordonez3/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar\"\n",
    "\n",
    "# Ruta a los archivos gVCF\n",
    "gvcf_dir=\"$output_dir/gvcfs\"\n",
    "\n",
    "# Crear el directorio temporal si no existe\n",
    "tmp_dir=\"$gvcf_dir/tmp\"\n",
    "mkdir -p \"$tmp_dir\"\n",
    "\n",
    "# Verificar permisos de lectura y escritura\n",
    "if [ ! -r \"$tmp_dir\" ] || [ ! -w \"$tmp_dir\" ]; then\n",
    "  echo \"‚ùå Error: No tienes permisos de lectura/escritura en $tmp_dir\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "# Verificar si hay archivos g.vcf.gz\n",
    "gvcf_files=(\"$gvcf_dir\"/*.g.vcf.gz)\n",
    "if [ ! -e \"${gvcf_files[0]}\" ]; then\n",
    "  echo \"‚ö†Ô∏è No se encontraron archivos .g.vcf.gz en $gvcf_dir\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "# Mostrar cu√°ntas muestras encontr√≥\n",
    "echo \"üîé Se encontraron ${#gvcf_files[@]} muestras para importar.\"\n",
    "\n",
    "# Construir lista de inputs\n",
    "inputs=\"\"\n",
    "for file in \"${gvcf_files[@]}\"; do\n",
    "  inputs+=\" -V $file\"\n",
    "done\n",
    "\n",
    "# Lista completa de cromosomas\n",
    "chromosomes=(chr{1..22} chrX chrY)\n",
    "\n",
    "for chr in \"${chromosomes[@]}\"; do\n",
    "  workspace_path=\"$output_dir/my_database_$chr\"\n",
    "  \n",
    "  # Eliminar workspace corrupto si existe\n",
    "  if [ -d \"$workspace_path\" ]; then\n",
    "    echo \"üßπ Borrando workspace corrupto existente para $chr ...\"\n",
    "    rm -rf \"$workspace_path\"\n",
    "  fi\n",
    "\n",
    "  echo \"üöÄ Importando $chr ...\"\n",
    "  \n",
    "  # Ejecutar GenomicsDBImport con log espec√≠fico\n",
    "  $gatk GenomicsDBImport \\\n",
    "    $inputs \\\n",
    "    --genomicsdb-workspace-path \"$workspace_path\" \\\n",
    "    --tmp-dir \"$tmp_dir\" \\\n",
    "    --intervals \"$chr\" \\\n",
    "    &> \"$output_dir/log_GenomicsDBImport_$chr.txt\"\n",
    "\n",
    "  # Verificar resultado\n",
    "  if [ $? -eq 0 ]; then\n",
    "    echo \"‚úÖ $chr importado correctamente.\"\n",
    "  else\n",
    "    echo \"‚ùå Error al importar $chr. Revisa $output_dir/log_GenomicsDBImport_$chr.txt\"\n",
    "  fi\n",
    "done\n",
    "\n",
    "echo \"üéâ Proceso completo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961eda8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (984889335.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    for chr in {1..22} X Y; do\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "## GENOTIPIFICACION\n",
    "\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "for chr in {1..22} X Y; do\n",
    "  echo \"üß¨ Procesando chr$chr...\"\n",
    "  gatk GenotypeGVCFs \\\n",
    "    -R \"$reference\" \\\n",
    "    -V gendb://my_database_chr$chr \\\n",
    "    -O genotipos_chr${chr}.vcf.gz\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. FILTRADO DE VARIANTES\n",
    "\n",
    "reference=\"/home/yordonez3/Danny_OV_WES/concatenated_fastq/concatenated_all_fastq/hg38.fa\"\n",
    "\n",
    "for chr in {1..22} X Y; do\n",
    "  input_vcf=\"genotipos_chr${chr}.vcf.gz\"\n",
    "  output_vcf=\"genotipos_chr${chr}_filtered.vcf.gz\"\n",
    "  \n",
    "  if [ ! -s \"$input_vcf\" ]; then\n",
    "    echo \"‚ö†Ô∏è Archivo $input_vcf no existe o est√° vac√≠o, se omite.\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  echo \"üß¨ Filtrando variantes de $input_vcf...\"\n",
    "\n",
    "  gatk VariantFiltration \\\n",
    "    -R \"$reference\" \\\n",
    "    -V \"$input_vcf\" \\\n",
    "    --window 35 \\\n",
    "    --cluster 3 \\\n",
    "    --filter-name \"FS\" --filter \"FS > 30.0\" \\\n",
    "    --filter-name \"QD\" --filter \"QD < 2.0\" \\\n",
    "    --filter-name \"MQ\" --filter \"MQ < 30.0\" \\\n",
    "    -O \"$output_vcf\"\n",
    "done\n",
    "\n",
    "# Contar los SNPs obtenidos\n",
    "bcftools view -H -v snps geno_exo_28_filtered.vcf.gz | wc -l\n",
    "for chr in {1..22} X Y; do\n",
    "  echo \"Cromosoma $chr:\"\n",
    "  bcftools view -H -v snps genotipos_chr${chr}_filtered.vcf.gz | wc -l\n",
    "done\n",
    "\n",
    "\n",
    "#Criterios para el filtrado\n",
    "FS (Phred-scaled p-value using Fisher's exact test to detect strand bias)\n",
    "FS > 30.0: Filters variants with a Fisher Strand (FS) score greater than 30.0.\n",
    "\n",
    "QD es el valor de calidad de una variante dividido por la profundidad de cobertura en ese sitio espec√≠fico\n",
    "QD < 2.0: Filters variants with a Quality by Depth (QD) score less than 2.0.\n",
    "variantes con un valor QD menor que 2.0 ser√°n marcadas como filtradas.\n",
    "    \n",
    "MQ Mapping Quality MQ ‚â• 30, es un umbral com√∫nmente utilizado en muchos estudios. \n",
    "Se considera que un MQ de 30 o m√°s indica una alineaci√≥n confiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8790091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8da836-92d4-43c2-b042-9cfa90ce89b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "###PLINK\n",
    "\n",
    "mv geno_exo_28_filtered.vcf.gz geno_exo_28_filtered.vcf.gz.tbi /home/wovalle3/Samples/total_samples_pool/EXOMA/variantes/plink\n",
    "\n",
    "#Antes de empezar revisar que el archivo tenga los IDs de los SNPs\n",
    "bcftools view --no-header geno_exo_28_filtered.vcf.gz | head\n",
    "\n",
    "#En dado caso, anotar con bcftools\n",
    "mv Homo_sapiens_assembly38.dbsnp138.vcf.gz /home/wovalle3/LREY/variant_call/Plink_Rnaseq\n",
    "bcftools index Homo_sapiens_assembly38.dbsnp138.vcf.gz\n",
    "\n",
    "bcftools annotate --annotations Homo_sapiens_assembly38.dbsnp138.vcf.gz --columns ID --output geno_final.vcf.gz --output-type z geno_filt_annot.vcf.gz\n",
    "bcftools view --no-header geno_final.vcf.gz | head\n",
    "\n",
    "#La anotacion no permite el merge entre las poblaciones de referencia. Hacer sin anotar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eeca38-df1e-4b95-a9e6-54a0491cf173",
   "metadata": {},
   "outputs": [],
   "source": [
    "###PLINK\n",
    "VCF de entrada: geno_exo_28_filtered.vcf.gz\n",
    "\n",
    "bcftools view --no-header geno_exo_28_filtered.vcf.gz | head\n",
    "\n",
    "##1. Generar los bfiles con el archivo .vcf de mis muestras\n",
    "The first step for quality control (QC) analysis in PLINK starting from\n",
    "your VCF files is to convert the VCF file to PLINK format (BED, BIM, FAM).\n",
    "PLINK provides a tool called plink2 for this purpose. \n",
    "                                 \n",
    "plink --vcf geno_exo_28_filtered.vcf.gz --make-bed --out geno_plink\n",
    "\n",
    "#Results\n",
    "Total genotyping rate is 0.461463.\n",
    "14.853.128 variants and 18 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.434183.\n",
    "20.581.021 variants and 28 people pass filters and QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd17796-7701-49bc-9352-52a5a50d0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Perform QC analysis\n",
    "\n",
    "#Opciones de QC\n",
    "#Removing individuals with high missing genotype rates (--mind): --mind 0.05\n",
    "#Removing SNPs with high missingness (--geno): --geno 0.05\n",
    "#Removing SNPs with low minor allele frequency (--maf): --maf 0.01\n",
    "#Performing Hardy-Weinberg equilibrium (HWE) testing (--hwe): 1e-6\n",
    "#Removing SNPs with extreme heterozygosity (--het).\n",
    "#Identificaci√≥n de SNPs Duplicados (--list-duplicate-vars)\n",
    "#Filtrar por Identidad por Descendencia (IBD) (--genome y --rel-cutoff)\n",
    "\n",
    "#Usar comando geno 0.1 para que deje solamente SNPs con CR>90%\n",
    "plink --bfile geno_plink --geno 0.1  --make-bed --out geno_plink_fil1\n",
    "\n",
    "#Results\n",
    "Total genotyping rate is 0.461463.\n",
    "12.763.929 variants removed due to missing genotype data (--geno).\n",
    "2.089.199 variants and 18 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.434183.\n",
    "18.721.953 variants removed due to missing genotype data (--geno).\n",
    "1.859.068 variants and 28 people pass filters and QC.\n",
    "\n",
    "#Control de calidad para individuos con mind. Deja solamente casos CR>90%\n",
    "plink --bfile geno_plink_fil1 --mind 0.25 --make-bed --out geno_plink_fil2   ##Mejor hacerlo con 0.1 despues\n",
    "\n",
    "#Results\n",
    "Total genotyping rate in remaining samples is 0.943978.\n",
    "2.089.199 variants and 17 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.97497.\n",
    "1.859.068 variants and 28 people pass filters and QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21a123-5353-4395-b12c-667ae767bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Filtrar por MAF y HW\n",
    "\n",
    "#MAF: 0.01 remueve variantes con frecuencia de alelo menor a 1% (es dcir mutaciones y demas)\n",
    "plink --bfile geno_plink_fil2 --maf 0.01 --make-bed --out geno_plink_fil3\n",
    "\n",
    "#Results\n",
    "Total genotyping rate is 0.943978\n",
    "124.280 variants removed due to minor allele threshold(s)\n",
    "1.964.919 variants and 17 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.97497.\n",
    "3041 variants removed due to minor allele threshold(s)\n",
    "1.856.027 variants and 28 people pass filters and QC\n",
    "\n",
    "\n",
    "#HW\n",
    "plink --bfile geno_plink_fil3 --hwe 1e-6 --hwe-all --make-bed --out geno_plink_fil4\n",
    "\n",
    "#Results\n",
    "Total genotyping rate is 0.944006.\n",
    "--hwe: 960 variants removed due to Hardy-Weinberg exact test.\n",
    "1.963.959 variants and 17 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.974968.\n",
    "--hwe: 520 variants removed due to Hardy-Weinberg exact test.\n",
    "1.855.507 variants and 28 people pass filters and QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def49180-ef8c-4282-8446-85c48a0d3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform LD pruning in two steps:\n",
    "# Step 1: Generate list of SNPs to keep\n",
    "# We perform linkage disequilibrium (LD) pruning using:\n",
    "  # - a window size of 50 SNPs\n",
    "  # - a step size of 5 SNPs\n",
    "  # - r2 threshold of 0.2 (correlation between SNPs)\n",
    "\n",
    "plink --bfile geno_plink_fil4 --indep-pairwise 50 5 0.2 --out ld_pruned\n",
    "\n",
    "#Results \n",
    "Total genotyping rate is 0.944005.\n",
    "1.963.959 variants and 17 people pass filters and QC.\n",
    "Pruning complete.  1.668.064 of 1.963.959 variants removed.\n",
    "\n",
    "\n",
    "# Step 2: Apply LD pruning\n",
    "plink --bfile geno_plink_fil4 --extract ld_pruned.prune.in --make-bed --out geno_plink_fil5\n",
    "\n",
    "#Results \n",
    "Ambiguous sex IDs written to geno_plink_fil5.nosex .\n",
    "--extract: 1963959 variants remaining.\n",
    "Warning: At least 295894 duplicate IDs in --extract file.\n",
    "Total genotyping rate is 0.944005.\n",
    "1.963.959 variants and 17 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.974963.\n",
    "1.855.507 variants and 28 people pass filters and QC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa729d1-b456-4c08-8ce8-1856b075c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CODIGO ALEJANDRO\n",
    "\n",
    "!./plink2 --bfile exome_data \\\n",
    "--maf 0.01 \\\n",
    "--geno 0.1 \\\n",
    "--mind 0.1 \\\n",
    "--hwe 0.0001 \\\n",
    "--make-bed \\\n",
    "--out admixture_maf-0.01_geno-0.1_hwe-1e4\n",
    "\n",
    "# Perform LD pruning in two steps:\n",
    "# Step 1: Generate list of SNPs to keep\n",
    "# We perform linkage disequilibrium (LD) pruning using:\n",
    "  # - a window size of 50 SNPs\n",
    "  # - a step size of 5 SNPs\n",
    "  # - r2 threshold of 0.2 (correlation between SNPs)\n",
    "!./plink2 --bfile admixture_maf-0.01_geno-0.1_hwe-1e4 \\\n",
    "       --indep-pairwise 50 5 0.2 \\\n",
    "       --out ld_pruned\n",
    "\n",
    "# Step 2: Apply LD pruning\n",
    "!./plink2 --bfile admixture_maf-0.01_geno-0.1_hwe-1e4 \\\n",
    "       --extract ld_pruned.prune.in \\\n",
    "       --make-bed \\\n",
    "       --out admixture_LD_QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafae2ba-414a-419c-a7e7-befe2dbf832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Set-missing-var-ids para mis datos y el panel de referencia\n",
    "\n",
    "#El comando set-missing-var-ids en PLINK se utiliza para asignar \n",
    "#identificadores (IDs) a los SNPs que no tienen un ID en el archivo BIM\n",
    "\n",
    "plink --bfile geno_plink_fil5 --set-missing-var-ids chr@:#:\\$2:\\$1 --make-bed --out genoexo_NoMissVar\n",
    "    \n",
    "#Results\n",
    "Total genotyping rate is 0.944005.\n",
    "1.963.959 variants and 17 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.974963.\n",
    "1.855.507 variants and 28 people pass filters and QC.\n",
    "\n",
    "head genoexo_NoMissVar.bim\n",
    "#results \n",
    "1\tchr1:14671:G:A\t0\t14671\tA\tG\n",
    "1\tchr1:14677:G:A\t0\t14677\tA\tG\n",
    "1\tchr1:14685:T:C\t0\t14685\tT\tC\n",
    "1\tchr1:14758:G:A\t0\t14758\tA\tG    \n",
    "\n",
    "\n",
    "#Esto lo hago desde la carpeta de FinalReferencePanel si no se tiene \n",
    "#plink --bfile extractedChrAll --set-missing-var-ids chr@:#:\\$2:\\$1 --make-bed --out extractedChrAll_NoMissVar\n",
    "    \n",
    "#Results\n",
    "23.886.383 variants loaded from .bim file.\n",
    "969 people (0 males, 0 females, 969 ambiguous) loaded from .fam.\n",
    "Total genotyping rate is 0.999872.\n",
    "23.886.383 variants and 969 people pass filters and QC.\n",
    "\n",
    "#Mover los archivos a la carpeta desde donde se esta haciendo el analisis\n",
    "mv extractedChrAll_NoMissVar* /home/wovalle3/Samples/total_samples_pool/EXOMA/variantes/plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f3d2e-04ff-4c1d-b9b8-f766705e8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Encontrar variantes que se comparten entre la base de referencia y la mia\n",
    "\n",
    "#Para asegurarte de que el panel de referencia tiene exactamente las mismas \n",
    "#variantes que tu archivo antes de realizar un merge en PLINKls\n",
    "\n",
    "comm -12 <(sort genoexo_NoMissVar.bim) <(sort extractedChrAll_NoMissVar.bim) > variantes_comunes.txt\n",
    "wc -l variantes_comunes.txt #119.776 compartidas  #111.293\n",
    "\n",
    "plink --bfile extractedChrAll_NoMissVar --extract variantes_comunes.txt --make-bed --out Ref_comunes\n",
    "\n",
    "#Results\n",
    "Total genotyping rate is 0.99987.\n",
    "119.776 variants and 969 people pass filters and QC\n",
    "\n",
    "Total genotyping rate is 0.999874.\n",
    "111.293 variants and 969 people pass filters and QC.\n",
    "\n",
    "plink --bfile genoexo_NoMissVar --extract variantes_comunes.txt --make-bed --out genoexo_comunes\n",
    "#Results\n",
    "Total genotyping rate is 0.95625.\n",
    "119.776 variants and 17 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.978565.\n",
    "111.293 variants and 28 people pass filters and QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a24a4a-d462-44c2-b002-654811d2255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Merge del panel de referencia con mis datos\n",
    "\n",
    "plink --bfile Ref_comunes --bmerge genoexo_comunes --make-bed --out merged_set_28\n",
    "\n",
    "(969 + 17)\n",
    "Total genotyping rate is 0.999118.\n",
    "119.776 variants and 986 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.999275.\n",
    "111.293 variants and 997 people pass filters and QC.\n",
    "\n",
    "plink --bfile merged_set_28 --geno 0.10  --make-bed --out merged_set_fil28\n",
    "\n",
    "#results\n",
    "0 variants removed due to missing genotype data (--geno).\n",
    "119776 variants and 986 people pass filters and QC.\n",
    "\n",
    "0 variants removed due to missing genotype data (--geno).\n",
    "111293 variants and 997 people pass filters and QC\n",
    "\n",
    "#PCA con los resultados\n",
    "plink --bfile merged_set_fil28 --pca --out pca_results_28\n",
    "scp -r wovalle3@bio-compjord01.biosci.gatech.edu:/home/wovalle3/Samples/total_samples_pool/EXOMA/variantes/plink/pca_results_28.eigenval /Users/wen/Documents/\n",
    "scp -r wovalle3@bio-compjord01.biosci.gatech.edu:/home/wovalle3/Samples/total_samples_pool/EXOMA/variantes/plink/pca_results_28.eigenvec /Users/wen/Documents/\n",
    "\n",
    "#Los archivos generados por PLINK para el an√°lisis de PCA (pca_results.eigenvec y pca_results.eigenval) \n",
    "#son archivos de texto que contienen los resultados del an√°lisis de componentes principales. \n",
    "#Puedes abrir y analizar estos archivos en R para visualizaci√≥n y an√°lisis adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebba510-004f-48ef-9d05-bdbc479dea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.\tGenerar un nuevo archivo recodificado para Admixture\n",
    "\n",
    "plink --bfile merged_set_fil28 --recode12 --out Final_admixture28\n",
    "\n",
    "#results\n",
    "Total genotyping rate is 0.999118.\n",
    "119.776 variants and 986 people pass filters and QC.\n",
    "\n",
    "Total genotyping rate is 0.999275.\n",
    "111.293 variants and 997 people pass filters and QC.\n",
    "\n",
    "#Instalar Admixture en el servidor \n",
    "wget https://dalexander.github.io/admixture/binaries/admixture_linux-1.3.0.tar.gz\n",
    "\n",
    "#Descomprimir el archivo tar.gz\n",
    "tar -zxvf admixture_linux-1.3.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb22ba-c710-4b74-a31b-692c4c8eeadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Correr admixture desde donde esta el archivo ped\n",
    "/home/wovalle3/ADMIXTURE/dist/admixture_linux-1.3.0/admixture Final_admixture28.ped 3\n",
    "\n",
    "#Results\n",
    "Summary: \n",
    "Converged in 13 iterations (239.995 sec)\n",
    "Loglikelihood: -85308375.284505\n",
    "Fst divergences between estimated populations: \n",
    "\tPop0\tPop1\t\n",
    "Pop0\t\n",
    "Pop1\t0.136\t\n",
    "Pop2\t0.181\t0.123\t\n",
    "Writing output files.\n",
    "\n",
    "Converged in 16 iterations (249.68 sec)\n",
    "Loglikelihood: -71583396.008181\n",
    "Fst divergences between estimated populations: \n",
    "\tPop0\tPop1\t\n",
    "Pop0\t\n",
    "Pop1\t0.134\t\n",
    "Pop2\t0.182\t0.126\t\n",
    "Writing output files.\n",
    "\n",
    "#Pasar archivo Final_admixture.3.Q y merged_set.fam a pc para mirar resultados\n",
    "scp -r wovalle3@bio-compjord01.biosci.gatech.edu:/home/wovalle3/Samples/total_samples_pool/EXOMA/variantes/plink/Final_admixture28.3.Q /Users/wen/Documents/\n",
    "scp -r wovalle3@bio-compjord01.biosci.gatech.edu:/home/wovalle3/Samples/total_samples_pool/EXOMA/variantes/plink/merged_set_28.fam /Users/wen/Documents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e61480-5e0f-4dea-bb9b-6a9e1a879ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
